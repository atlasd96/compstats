---
title: "Atlas-PS 10"
author: "David Atlas"
date: "10/31/2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Problem 1
We define an orthogonal function family to be a set of functions $F$ for which $<f, g> = 0 \forall f \neq g, f \in F, g \in F$. Here, 
we define the inner product of two functions with respect to a weight function $w(x)$ to be $\int_D f(x)g(x)w(x)dx$. In the given problem,  $w(x) = 1$, so we 
needn't worry about it.

We start by asserting 3 commonly known identities.
\begin{align}
sin(x)sin(y) &= \frac{1}{2}(cos(x-y) - cos(x + y)) \\
cos(x)cos(y) &= \frac{1}{2}(cos(x+y) + cos(x - y)) \\
sin(x)cos(x) &= \frac{1}{2}(sin(x+y) + sin(x-y))
\end{align}

As both $\int_0^{2\pi}cos(kx) dx = 0$ and $\int_0^{2\pi}sin(kx) dx = 0$ are trivial for all $k \in \mathbb{N}$, we won't discuss the inner product of 1 and any of the functions in the family.

Next, we invoke the identity to say the following: 

Let $k, j$ be natural numbers. Without loss of generalization, we can say that  $k < j$.
\begin{align*}
\int_0^{2\pi}cos(jx)cos(kx)dx &= 
\frac{1}{2} \int_0^{2 \pi} cos((j + k) x) + cos((j - k )x) \\
\frac{1}{2} [\frac{sin((j+k)x)}{j+k} + \frac{sin((j - k)x)}{j-k}\vert_0^{2\pi}.
\end{align*}

Note that $\int_0^{2\pi}sin(kx) dx = 0$ , implying that $\int_0^{2\pi}cos(jx)cos(kx)dx = 0 \forall j, k \in \mathbb{N}, j\neq k$.

Let $k, j$ be natural numbers. Without loss of generalization, we can say that  $k < j$.
\begin{align*}
\int_0^{2\pi}sin(jx)sin(kx)dx &= 
\frac{1}{2} \int_0^{2 \pi} cos((j - k) x) - cos((j + k )x) \\
\frac{1}{2} [\frac{sin((j-k)x)}{j-k} - \frac{sin((j + k)x)}{j+k}] \vert_0^{2\pi}.
\end{align*}
Again, both terms are equal to zero for any natural numbers $j$ and $k$ that aren't equal to each other. 

Let $k, j$ be natural numbers. Without loss of generalization, we can say that  $k < j$$.
\begin{align*}
\int_0^{2\pi}cos(jx)sin(kx)dx &= 
\frac{1}{2} \int_0^{2 \pi} sin((j + k) x) + sin ((j - k )x) \\
\frac{1}{2} [-\frac{cos((j+k)x)}{j+k} - \frac{cos((j-k)x)}{j-k}] \vert_0^{2\pi}
\end{align*}

We note that $cos(k (2 \pi)) = 1 \forall k \in \mathbb{N}$ and $cos(0) = 1$. Therefore, for any natural 
numbers $j$ and $k$, $\frac{1}{2} [-\frac{cos((j+k)x)}{j+k} - \frac{cos((j-k)x)}{j-k}] \vert_0^{2\pi}= -1 - (-1)= 0$.

We should note here that 
\[
\int_0^{2\pi}sin(kx)cos(kx)dx
\]
would result in a divide-by-zero issue above. For this, we note that 
$\int_0^{2\pi}sin(kx)cos(kx)dx = -\frac{cos^2(kx)}{2k} \vert_0^{2\pi} = -\frac{1}{2k} - (- \frac{1}{2k}) =0$.

Therefore, we have show the Fourier Trigonometric Family to be orthogonal on $0 \leq x \leq 2\pi$ with respect to weight $w(x)=1$.

# Problem 2
## a) 
To show that if ${q_i(x)}$ is a set of orthogonal functions, then it is a linearly independent set, we use a proof by contradiction.
First, note that a set of orthogonal functions can trivialy be normalized, so we can assume without loss of generality that 
it is an orthonormal set.

Suppose it is not a linearly independent set. Then there must exist a function $q_k(x)$ such that $q_k(x) = \sum_{i=1}^{k-1} c_i q_i(x)$, 
where $\exists i \in [1, k-1]$ such that $c_i \neq 0$. 
(Note that we assume here that it is the last function in the set, $q_k$ out of notational convenience, but it doesn't really matter.)

Next, note that we can rewrite the sequence of constants, $c_i$ as 
\[
c_i = <q_k(x), q_i(x)>,  \forall 1 \leq i \leq k-1.
\]

Because the set of functions is orthogonal, we know that $<q_k(x), q_i(x)>=0$ for all $i \in [1, k-1]$. However, 
this is a contradiction, because $\nexists i \in [1, k-1]$ such that $c_i \neq 0$.

Therefore the set must be linearly independent, and we have show that a set of othogonal functions must be linearly independent too.

## b)
We first define $\rm{IMSE} = \int_D \rm{E}[(\hat{f}(x) - f(x))^2]$. 
Also, the expected value of $f(x)$ is a constant with respect to $\hat{f}(x)$.

Noting that the variance of $\hat{f}(x)$ can be written as $\rm{V}(\hat{f}) = \rm{E}[\hat{f}(x)^2] - \rm{E}[\hat{f}(x)]^2$, we rewrite $\rm{IMSE}$:
\begin{align*}
\rm{IMSE} &= \int_D \rm{E}[(\hat{f}(x) - f(x))^2] \\
&=\int_D \rm{E}[(\hat{f}(x)^2] - 2\rm{E}[(\hat{f}(x)f(x)] +  \rm{E}[f(x)^2] \\
&=\int_D \rm{V}(\hat{f})- 2\rm{E}[(\hat{f}(x)]f(x) +  f(x)^2 + \rm{E}[\hat{f})]^2 \\
&=\int_D \rm{V}(\hat{f}) + (\rm{E}[\hat{f}(x)] - f(x))^2 \\
&= \rm{IV}(\hat{f}) + \rm{ISB}(\hat{f}).
\end{align*}

# Problem 3
First, $\vert\vert\sum_{i=1}^m q_i\vert\vert^2$ can be expanded to be equal to $\sum_{i=1}^m \vert\vert q_i\vert\vert^2 + \sum_{j \neq k} \vert\vert q_j q_k \vert\vert $. Because the set of functions are orthogonal, 
$\sum_{j \neq k} \vert\vert q_j q_k=0 \vert\vert$. Therefore, 
$\vert\vert\sum_{i=1}^m q_i\vert\vert^2 = \sum_{i=1}^m \vert\vert q_i^2\vert\vert$. Under the L2 norm, 
$\sum_{i=1}^m \vert\vert q_i^2\vert\vert = \sum_{i=1}^m \vert\vert q_i\vert\vert^2$.

If each of the $q_k$ are orthonormal, the value of the expression will always evaluate to $m$, as it
will be the sum of $m$ functions equal to 1 over the space.

This expression may not hold under other norms, as the last step above, 
$\sum_{i=1}^m \vert\vert q_i^2\vert\vert = \sum_{i=1}^m \vert\vert q_i\vert\vert^2$ does not
necessarily hold under norms that are not L2, as the squared step is not transitive under the norm.

# Problem 4
## a)
We derive the first 4 Chebyshev Polynomials using the following formula:
\[
q_i(x) = x^i - \sum_{j=1}^{i-1}<q_i, q_j> q_j(x).
\]

We then normalize them as follows:
\[
q_i^*(x) = \frac{q_i(x)}{\vert\vert q_i(x) \vert\vert}
\]

where the norm is defined as the inner product of the function and itself.

Note that the when $i + j$ is odd, the inner product is zero. 

\begin{align*}
q_0(x) &= 1 \\
q_1(x) &= x - 0 \\
q_2(x) &= (x^2 - \frac{\pi}{8}) \frac{128}{\pi (8 - 4 \pi + \pi^2)} \\
q_3(x) &= (x^3 - \frac{\pi}{16} \frac{512}{\pi(20+pi^2)}.
\end{align*}

(I did the algebra using Wolfram Alpha, using the formula above.)

## b)
Next, we create a function that is the sum of the terms and see if it fits the $N(0, .3)$ data from 
Blackboard.

```{r}
data <- scan("Orthogonal.txt")
f <- function(x) 1 + (x) + 
      ((x^2 - pi/8) * (128 / (pi * (8 - 4 * pi + pi^2)))) + 
      ((x^3 - pi/16) * 512 /  (pi * (20 + pi^2)))

hist(data, probability = T)
x <- seq(-1, 1, .01)
plot(x, f(x))
lines(x, f(x))
```

# Problem 5
## a)
The cubic spline described is a natural cubic spline, as $f^{\prime \prime}(-1) = f^{\prime \prime}(1) = 0$ and 












